colnames(qq) = c("NO","YES")
qq
qq=as.data.frame(predict(model_RF, newdata=valid_caret[,!names(valid_caret) %in% c("classLabel")], type="prob"))
colnames(qq) = c("NO","YES")
qq
answer = as.data.frame(qq$NO<qq$YES)
answer_prop = ifelse(answer==FALSE, "no.", "yes.")
colnames(answer_prop) = "classe"
qplot(answer_prop, colour=valid_caret[,"classLabel"])
confusionMatrix(answer_prop,valid_caret[,"classLabel"])
answer_prop
qq
answer = as.data.frame(qq$NO=<qq$YES)
qq$NO == qq$YES
answer = as.data.frame(qq$NO < qq$YES)
answer
length(qq)
qq
dim(qq)
View(valid_caret)
col=c("yellow", "black"), legend=FALSE)
missmap(train_caret, main="Titanic Training Data - Missings Map",
col=c("yellow", "black"), legend=FALSE)
missmap(valid_caret, main="Titanic Training Data - Missings Map",
col=c("yellow", "black"), legend=FALSE)
mice = mice(valid_caret, method="rf")
outmice = complete(mice)
valid_caret = outmice
missmap(train_caret, main="Titanic Training Data - Missings Map",
col=c("yellow", "black"), legend=FALSE)
missmap(valid_caret, main="Titanic Training Data - Missings Map",
col=c("yellow", "black"), legend=FALSE)
PREDICTION = predict(model_RF, newdata=valid_caret[,!names(valid_caret) %in% c("classLabel")])
confusionMatrix(PREDICTION,valid_caret[,"classLabel"])
control <- trainControl(method="cv", number=10, repeats=5)
gbmGrid <-  expand.grid(interaction.depth = c(1, 5, 9),
n.trees = (1:30)*50,
shrinkage = 0.1,
n.minobsinnode = 20)
model_GBM = train(classLabel~., data=train_caret[,!names(train_caret) %in% c("v7","v18")], method="gbm", trControl=control, tuneGrid=gbmGrid)
PREDICTION = predict(model_GBM, newdata=valid_caret[,!names(train_caret) %in% c("classLabel")])
confusionMatrix(PREDICTION,valid_caret[,"classLabel"])
train_caret = train
valid_caret = valid
train_caret$v17 = as.numeric(train_caret$v17)
train_caret$v19 = as.numeric(train_caret$v19)
train_caret$v29 = as.numeric(train_caret$v29)
valid_caret$v17 = as.numeric(valid_caret$v17)
valid_caret$v19 = as.numeric(valid_caret$v19)
valid_caret$v29 = as.numeric(valid_caret$v29)
train_caret = train_caret[,!names(train_caret) %in% c("v7","v18","v35")]
valid_caret = valid_caret[,!names(valid_caret) %in% c("v7","v18","v35")]
train_caret= knnImputation(train_caret[,!names(train_caret) %in% "classLabel"], k=75)
valid_caret = knnImputation(valid_caret[,!names(train_caret) %in% "classLabel"], k=25)
missmap(train_caret, main="Titanic Training Data - Missings Map",
col=c("yellow", "black"), legend=FALSE)
missmap(valid_caret, main="Titanic Training Data - Missings Map",
col=c("yellow", "black"), legend=FALSE)
table(train_caret$classLabel)
table(valid_caret$classLabel)
train_caret = downSample(train_caret[,!names(train_caret) %in% "classLabel"], train_caret$classLabel, yname = "classLabel")
table(train_caret$classLabel)
missmap(train_caret, main="Titanic Training Data - Missings Map",
col=c("yellow", "black"), legend=FALSE)
train_caret = train
valid_caret = valid
train_caret$v17 = as.numeric(train_caret$v17)
train_caret$v19 = as.numeric(train_caret$v19)
train_caret$v29 = as.numeric(train_caret$v29)
valid_caret$v17 = as.numeric(valid_caret$v17)
valid_caret$v19 = as.numeric(valid_caret$v19)
valid_caret$v29 = as.numeric(valid_caret$v29)
train_caret = train_caret[,!names(train_caret) %in% c("v7","v18","v35")]
valid_caret = valid_caret[,!names(valid_caret) %in% c("v7","v18","v35")]
train_caret= knnImputation(train_caret[,!names(train_caret) %in% "classLabel"], k=75)
valid_caret = knnImputation(valid_caret[,!names(valid_caret) %in% "classLabel"], k=25)
missmap(train_caret, main="Titanic Training Data - Missings Map",
col=c("yellow", "black"), legend=FALSE)
missmap(valid_caret, main="Titanic Training Data - Missings Map",
col=c("yellow", "black"), legend=FALSE)
train_caret = downSample(train_caret[,!names(train_caret) %in% "classLabel"], train_caret$classLabel, yname = "classLabel")
```
table(train_caret$classLabel)
train_caret = train
valid_caret = valid
train_caret$v17 = as.numeric(train_caret$v17)
train_caret$v19 = as.numeric(train_caret$v19)
train_caret$v29 = as.numeric(train_caret$v29)
valid_caret$v17 = as.numeric(valid_caret$v17)
valid_caret$v19 = as.numeric(valid_caret$v19)
valid_caret$v29 = as.numeric(valid_caret$v29)
train_caret = train_caret[,!names(train_caret) %in% c("v7","v18","v35")]
valid_caret = valid_caret[,!names(valid_caret) %in% c("v7","v18","v35")]
View(train_caret)
train_caret= knnImputation(train_caret[,!names(train_caret) %in% "classLabel"], k=75)
valid_caret = knnImputation(valid_caret[,!names(valid_caret) %in% "classLabel"], k=25)
View(train_caret)
View(train_caret)
train_caret= knnImputation(train_caret[,!names(train_caret) %in% "classLabel"], k=75)
valid_caret = knnImputation(valid_caret[,!names(valid_caret) %in% "classLabel"], k=25)
train_caret$classLabel = train$classLabel
valid_caret$classLabel = valid$classLabel
missmap(train_caret, main="Titanic Training Data - Missings Map",
col=c("yellow", "black"), legend=FALSE)
missmap(valid_caret, main="Titanic Training Data - Missings Map",
col=c("yellow", "black"), legend=FALSE)
train_caret = downSample(train_caret[,!names(train_caret) %in% "classLabel"], train_caret$classLabel, yname = "classLabel")
control <- trainControl(method="cv", number=10, repeats=5)
model_RF = train(classLabel~., data=train_caret, method="rf", preProcess="range", trControl=control, tuneGrid = expand.grid(.mtry = c(2:6)),  n.tree=188, maxit=2000, importance=TRUE)
PREDICTION = predict(model_RF, newdata=valid_caret[,!names(valid_caret) %in% c("classLabel")])
confusionMatrix(PREDICTION,valid_caret[,"classLabel"])
my_tree_two <- rpart(classLabel ~., data = train_caret, method = "class", control = rpart.control(minsplit = 50, cp = 0))
qq=as.data.frame(predict(my_tree_two, valid_caret[,!names(valid_caret) %in% c("classLabel")]))
colnames(qq) = c("NO","YES")
qq
answer = as.data.frame(qq$NO<qq$YES)
answer_prop = ifelse(answer==FALSE, "no.", "yes.")
colnames(answer_prop) = "classe"
qplot(answer_prop, colour=valid_caret[,"classLabel"])
confusionMatrix(answer_prop,valid_caret[,"classLabel"])
gbmGrid <-  expand.grid(interaction.depth = c(1, 5, 9),
n.trees = (1:30)*50,
shrinkage = 0.1,
n.minobsinnode = 20)
model_GBM = train(classLabel~., data=train_caret[,!names(train_caret) %in% c("v7","v18")], method="gbm", trControl=control, tuneGrid=gbmGrid)
PREDICTION = predict(model_GBM, newdata=valid_caret[,!names(valid_caret) %in% c("classLabel")])
confusionMatrix(PREDICTION,valid_caret[,"classLabel"])
PREDICTION = predict(model_RF, newdata=valid_caret[,!names(valid_caret) %in% c("classLabel")])
confusionMatrix(PREDICTION,valid_caret[,"classLabel"])
train_caret = train
valid_caret = valid
train_caret$v17 = as.numeric(train_caret$v17)
train_caret$v19 = as.numeric(train_caret$v19)
train_caret$v29 = as.numeric(train_caret$v29)
valid_caret$v17 = as.numeric(valid_caret$v17)
valid_caret$v19 = as.numeric(valid_caret$v19)
valid_caret$v29 = as.numeric(valid_caret$v29)
train_caret = train_caret[,!names(train_caret) %in% c("v7","v18","v35")]
valid_caret = valid_caret[,!names(valid_caret) %in% c("v7","v18","v35")]
train_caret= knnImputation(train_caret[,!names(train_caret) %in% "classLabel"], k=75)
valid_caret = knnImputation(valid_caret[,!names(valid_caret) %in% "classLabel"], k=25)
train_caret$classLabel = train$classLabel
valid_caret$classLabel = valid$classLabel
missmap(train_caret, main="Titanic Training Data - Missings Map",
col=c("yellow", "black"), legend=FALSE)
missmap(valid_caret, main="Titanic Training Data - Missings Map",
col=c("yellow", "black"), legend=FALSE)
qq=as.data.frame(predict(my_tree_two, valid_caret[,!names(valid_caret) %in% c("classLabel")]))
colnames(qq) = c("NO","YES")
qq
answer = as.data.frame(qq$NO<qq$YES)
answer_prop = ifelse(answer==FALSE, "no.", "yes.")
colnames(answer_prop) = "classe"
qplot(answer_prop, colour=valid_caret[,"classLabel"])
confusionMatrix(answer_prop,valid_caret[,"classLabel"])
smote_train <- SMOTE(classLabel ~ ., data  = train_caret)
table(smote_train$Class)
table(smote_train$classLabel)
table(train_caret$classLabel)
View(smote_train)
?SMOTE
smote_train <- SMOTE(classLabel ~ ., data  = train_caret, perc.under = 500)
table(smote_train$classLabel)
smote_train <- SMOTE(classLabel ~ ., data  = train_caret, perc.under = 500, perc.over = 0)
table(smote_train$classLabel)
smote_train <- SMOTE(classLabel ~ ., data  = train_caret, perc.under = 500, perc.over = 200)
table(smote_train$classLabel)
table(train_caret$classLabel)
summary(train)
smote_train <- SMOTE(classLabel ~ ., data  = train_caret, perc.under = 500, perc.over = 200)
table(smote_train$classLabel)
table(train_caret$classLabel)
smote_train <- SMOTE(classLabel ~ ., data  = train_caret, perc.under = 0, perc.over = 200)
table(smote_train$classLabel)
train_caret = downSample(train_caret[,!names(train_caret) %in% "classLabel"], train_caret$classLabel, yname = "classLabel")
table(train_caret$classLabel)
model_RF = train(classLabel~., data=train_caret, method="rf", preProcess="range", trControl=control, tuneGrid = expand.grid(.mtry = c(2:6)),  n.tree=188, maxit=2000, importance=TRUE, metric="ROC")
control <- trainControl(method="cv", number=10, repeats=5, classProbs = TRUE)
model_RF = train(classLabel~., data=train_caret, method="rf", preProcess="range", trControl=control, tuneGrid = expand.grid(.mtry = c(2:6)),  n.tree=188, maxit=2000, importance=TRUE, metric="ROC")
PREDICTION = predict(model_RF, newdata=valid_caret[,!names(valid_caret) %in% c("classLabel")])
confusionMatrix(PREDICTION,valid_caret[,"classLabel"])
control <- trainControl(method="cv", number=10, repeats=5, classProbs = TRUE)
gbmGrid <-  expand.grid(interaction.depth = c(1, 5, 9),
n.trees = (1:30)*50,
shrinkage = 0.1,
n.minobsinnode = 20)
model_GBM = train(classLabel~., data=train_caret, method="gbm", trControl=control, tuneGrid=gbmGrid)
PREDICTION = predict(model_GBM, newdata=valid_caret[,!names(valid_caret) %in% c("classLabel")])
confusionMatrix(PREDICTION,valid_caret[,"classLabel"])
model_GBM = train(classLabel~., data=train_caret, method="gbm", trControl=control, tuneGrid=gbmGrid, metric="ROC")
PREDICTION = predict(model_GBM, newdata=valid_caret[,!names(valid_caret) %in% c("classLabel")])
confusionMatrix(PREDICTION,valid_caret[,"classLabel"])
?train
control <- trainControl(method="cv", number=10, repeats=5, classProbs = TRUE)
model_RF = train(classLabel~., data=train_caret, method="rf", preProcess="range", trControl=control, tuneGrid = expand.grid(.mtry = c(2:6)),  n.tree=188, maxit=2000, importance=TRUE)
PREDICTION = predict(model_RF, newdata=valid_caret[,!names(valid_caret) %in% c("classLabel")])
confusionMatrix(PREDICTION,valid_caret[,"classLabel"])
?trainControl
control <- trainControl(method="cv", number=10, repeats=5, classProbs = FALSE)
model_RF = train(classLabel~., data=train_caret, method="rf", preProcess="range", trControl=control, tuneGrid = expand.grid(.mtry = c(2:6)),  n.tree=188, maxit=2000, importance=TRUE)
PREDICTION = predict(model_RF, newdata=valid_caret[,!names(valid_caret) %in% c("classLabel")])
confusionMatrix(PREDICTION,valid_caret[,"classLabel"])
control <- trainControl(method="repeatedcv", number=10, repeats=5, classProbs = TRUE, summaryFunction = twoClassSummary)
model_RF = train(classLabel~., data=train_caret, method="rf", preProcess="range", trControl=control, tuneGrid = expand.grid(.mtry = c(2:6)),  n.tree=188, maxit=2000, importance=TRUE, metric="ROC")
installed.packages("pROC")
install.packages("pROC")
model_RF = train(classLabel~., data=train_caret, method="rf", preProcess="range", trControl=control, tuneGrid = expand.grid(.mtry = c(2:6)),  n.tree=188, maxit=2000, importance=TRUE, metric="ROC")
PREDICTION = predict(model_RF, newdata=valid_caret[,!names(valid_caret) %in% c("classLabel")])
confusionMatrix(PREDICTION,valid_caret[,"classLabel"])
control <- trainControl(method="cv", number=10, repeats=5, classProbs = TRUE, summaryFunction = twoClassSummary)
model_RF = train(classLabel~., data=train_caret, method="rf", preProcess="range", trControl=control, tuneGrid = expand.grid(.mtry = c(2:6)),  n.tree=188, maxit=2000, importance=TRUE, metric="ROC")
PREDICTION = predict(model_RF, newdata=valid_caret[,!names(valid_caret) %in% c("classLabel")])
confusionMatrix(PREDICTION,valid_caret[,"classLabel"])
BC.adaboost <- adaboost.M1(classLabel ~.,data=train_caret,mfinal=25, control=rpart.control(maxdepth=3))
library(rpart)
BC.adaboost <- adaboost.M1(classLabel ~.,data=train_caret,mfinal=25, control=rpart.control(maxdepth=3))
install.packages("adabag")
library("adabag")
BC.adaboost <- adaboost.M1(classLabel ~.,data=train_caret,mfinal=25, control=rpart.control(maxdepth=3))
library(adabag)
BC.adaboost <- adaboost.M1(classLabel ~.,data=train_caret,mfinal=25, control=rpart.control(maxdepth=3))
control <- trainControl(method="cv", number=10, repeats=5, classProbs = TRUE)
BC.adaboost <- train(classLabel~., data=train_caret, method="AdaBoost.M1", preProcess="range", trControl=control, tuneGrid = expand.grid(.mtry = c(2:6)),  n.tree=188, maxit=2000, importance=TRUE, metric="ROC")
BC.adaboost <- train(classLabel~., data=train_caret, method="AdaBoost.M1", preProcess="range", trControl=control,  importance=TRUE, metric="ROC")
BC.adaboost.pred <- predict.boosting(BC.adaboost,newdata=valid_caret[,!names(valid_caret) %in% c("classLabel")])
train = read.csv(file="Training.csv", header = TRUE,  fill=TRUE, sep = ';')
valid = read.csv(file="Validation.csv", header = TRUE, fill = TRUE, sep = ';')
library(caret); library(kernlab); library(ISLR); library(RANN);
library(DMwR);library(MASS); library(randomForest); library(rpart)
train_caret = train
valid_caret = valid
train_caret$v17 = as.numeric(train_caret$v17)
train_caret$v19 = as.numeric(train_caret$v19)
train_caret$v29 = as.numeric(train_caret$v29)
valid_caret$v17 = as.numeric(valid_caret$v17)
valid_caret$v19 = as.numeric(valid_caret$v19)
valid_caret$v29 = as.numeric(valid_caret$v29)
train_caret = train_caret[,!names(train_caret) %in% c("v7","v18","v35")]
valid_caret = valid_caret[,!names(valid_caret) %in% c("v7","v18","v35")]
train_caret= knnImputation(train_caret[,!names(train_caret) %in% "classLabel"], k=75)
valid_caret = knnImputation(valid_caret[,!names(valid_caret) %in% "classLabel"], k=25)
train_caret$classLabel = train$classLabel
valid_caret$classLabel = valid$classLabel
missmap(train_caret, main="Titanic Training Data - Missings Map",
col=c("yellow", "black"), legend=FALSE)
library("Amelia")
missmap(train_caret, main="Titanic Training Data - Missings Map",
col=c("yellow", "black"), legend=FALSE)
missmap(valid_caret, main="Titanic Training Data - Missings Map",
col=c("yellow", "black"), legend=FALSE)
train_caret = downSample(train_caret[,!names(train_caret) %in% "classLabel"], train_caret$classLabel, yname = "classLabel")
control <- trainControl(method="cv", number=10, repeats=5, classProbs = TRUE)
treebag <- train(classLabel ~ ., data = train_caret,
method = "treebag",
nbagg = 50,
metric = "ROC",
trControl = ctrl)
treebag <- train(classLabel ~ ., data = train_caret,
method = "treebag",
nbagg = 50,
metric = "ROC",
trControl = control)
model_treebag <- train(classLabel ~ ., data = train_caret,
method = "treebag",
nbagg = 50,
metric = "ROC",
trControl = control)
PREDICTION = predict(model_treebag, newdata=valid_caret[,!names(valid_caret) %in% c("classLabel")])
confusionMatrix(PREDICTION,valid_caret[,"classLabel"])
setwd("JOB-hunting/Kreditech_test/")
train = read.csv(file="Training.csv", header = TRUE,  fill=TRUE, sep = ';')
valid = read.csv(file="Validation.csv", header = TRUE, fill = TRUE, sep = ';')
registerDoParallel(clust)
library(caret); library(kernlab); library(ISLR); library(RANN);
library(DMwR);library(MASS); library(randomForest); library(rpart)
train_caret = train
valid_caret = valid
train_caret$v17 = as.numeric(train_caret$v17)
train_caret$v19 = as.numeric(train_caret$v19)
train_caret$v29 = as.numeric(train_caret$v29)
valid_caret$v17 = as.numeric(valid_caret$v17)
valid_caret$v19 = as.numeric(valid_caret$v19)
valid_caret$v29 = as.numeric(valid_caret$v29)
train_caret = train_caret[,!names(train_caret) %in% c("v7","v18")]
valid_caret = valid_caret[,!names(valid_caret) %in% c("v7","v18")]
library("Amelia")
missmap(train_caret, main="Training Data - Missings Map",
col=c("yellow", "black"), legend=FALSE)
train_caret_v2 = rfImpute(classLabel~., train_caret)
missmap(train_caret_v2, main="Training Data - Missings Map",
col=c("yellow", "black"), legend=FALSE)
train_caret_v3 = downSample(train_caret_v2[,!names(train_caret_v2) %in% "classLabel"], train_caret_v2$classLabel, yname = "classLabel")
train_nsv = nearZeroVar(train_caret_v3, saveMetrics = TRUE)
train_nsv
control <- trainControl(method="cv", number=10, repeats=5, classProbs = TRUE)
model_RF = train(classLabel~., data=train_caret_v3, method="rf", preProcess="range", trControl=control, tuneGrid = expand.grid(.mtry = c(2:6)),  n.tree=188, maxit=2000, importance=TRUE, metric="ROC", proximity=TRUE)
PREDICTION = predict(model_RF, newdata=valid_caret[!names(valid_caret) %in% c("classLabel")])
confusionMatrix(PREDICTION,valid_caret[,"classLabel"])
PREDICTION = predict(model_RF, newdata=valid_caret[!names(valid_caret) %in% c("classLabel")])
PREDICTION
str(valid_caret)
missmap(valid_caret, main="Validation Data - Missings Map",
col=c("yellow", "black"), legend=FALSE)
valid_caret_v2 = rfImpute(classLabel~., valid_caret)
missmap(valid_caret_v2, main="Validation Data - Missings Map",
col=c("yellow", "black"), legend=FALSE)
PREDICTION = predict(model_RF, newdata=valid_caret_v2[!names(valid_caret_v2) %in% c("classLabel")])
confusionMatrix(PREDICTION,valid_caret_v2[,"classLabel"])
library("CORElearn")
install.packages("CORElearn")
library("CORElearn")
md <- CoreModel(classLabel ~ ., train_caret_v2, model="rf", rfNoTrees=30, maxThreads=1)
outliers <- rfOutliers(md, train_caret_v2)
plot(abs(outliers))
plot(abs(outliers), col=train_caret_v2$classLabel)
plot(md, train_caret_v2, graphType="outliers")
str(train_caret_v2)
md
train_caret_v3 = train_caret_v2[,.(v2)]
train_caret_v3 = train_caret_v2[,-c(v2)]
train_caret_v3 = train_caret_v2[,-c("v2")]
train_caret_v3 = train_caret_v2[,-("v2")]
train_caret_v3 = subset(train_caret_v2,-v2)
train_caret_v3 = subset(train_caret_v2,-"v2")
?"subset"
train_caret_v3 = subset(train_caret_v2, select=-v2)
train_caret_v4 = downSample(train_caret_v3[,!names(train_caret_v3) %in% "classLabel"], train_caret_v3$classLabel, yname = "classLabel")
valid_caret_v3 = subset(valid_caret_v2, select=-v2)
model_RF = train(classLabel~., data=train_caret_v4, method="rf", preProcess="range", trControl=control, tuneGrid = expand.grid(.mtry = c(2:6)),  n.tree=188, maxit=2000, importance=TRUE, metric="ROC", proximity=TRUE)
PREDICTION = predict(model_RF, newdata=valid_caret_v3[!names(valid_caret_v3) %in% c("classLabel")])
confusionMatrix(PREDICTION,valid_caret_v3[,"classLabel"])
md <- CoreModel(classLabel ~ ., train_caret_v2, model="rf", rfNoTrees=30, maxThreads=1)
outliers <- rfOutliers(md, train_caret_v2)
plot(abs(outliers), col=train_caret_v2$classLabel)
outlier()
outliers
subset_I = abs(outliers) < 5
train_caret_v3 = train_caret_v2[subset_I,]
valid_caret_v3 = valid_caret_v2
train_caret_v4 = downSample(train_caret_v3[,!names(train_caret_v3) %in% "classLabel"], train_caret_v3$classLabel, yname = "classLabel")
control <- trainControl(method="cv", number=10, repeats=5, classProbs = TRUE)
model_RF = train(classLabel~., data=train_caret_v4, method="rf", preProcess="range", trControl=control, tuneGrid = expand.grid(.mtry = c(2:6)),  n.tree=188, maxit=2000, importance=TRUE, metric="ROC", proximity=TRUE)
model_RF_TRUE = randomForest(x = train_caret_v4[,!names(train_caret_v4) %in% c("classLabel")], y=train_caret_v4$classLabel, ntree=188, importance=TRUE, metric="ROC", proximity=TRUE)
PREDICTION = predict(model_RF, newdata=valid_caret_v3[!names(valid_caret_v3) %in% c("classLabel")])
confusionMatrix(PREDICTION,valid_caret_v3[,"classLabel"])
train_caret_v3 = downSample(train_caret_v2[,!names(train_caret_v2) %in% "classLabel"], train_caret_v2$classLabel, yname = "classLabel")
md <- CoreModel(classLabel ~ ., train_caret_v3, model="rf", rfNoTrees=30, maxThreads=1)
outliers <- rfOutliers(md, train_caret_v3)
plot(abs(outliers), col=train_caret_v3$classLabel)
subset_I = abs(outliers) < 5
valid_caret_v4 = valid_caret_v2
train_caret_v4 = train_caret_v3[subset_I,]
train_caret_v4 = train_caret_v3[subset_I,]
valid_caret_v4 = valid_caret_v2
control <- trainControl(method="cv", number=10, repeats=5, classProbs = TRUE)
model_RF = train(classLabel~., data=train_caret_v4, method="rf", preProcess="range", trControl=control, tuneGrid = expand.grid(.mtry = c(2:6)),  n.tree=188, maxit=2000, importance=TRUE, metric="ROC", proximity=TRUE)
PREDICTION = predict(model_RF, newdata=valid_caret_v4[!names(valid_caret_v4) %in% c("classLabel")])
confusionMatrix(PREDICTION,valid_caret_v4[,"classLabel"])
model_RF_TRUE = randomForest(x = train_caret_v4[,!names(train_caret_v4) %in% c("classLabel")], y=train_caret_v4$classLabel, ntree=188, importance=TRUE, metric="ROC", proximity=TRUE)
PREDICTION = predict(model_RF_TRUE, newdata=valid_caret_v4[!names(valid_caret_v4) %in% c("classLabel")])
str(train_caret_v4)
levels(valid_caret_v4$v9) = levels(train_caret_v4$v9)
levels(valid_caret_v4$v20) = levels(train_caret_v4$v20)
levels(valid_caret_v4$v41) = levels(train_caret_v4$v41)
levels(valid_caret_v4$v31) = levels(train_caret_v4$v31)
levels(valid_caret_v4$v36) = levels(train_caret_v4$v36)
levels(valid_caret_v4$v2) = levels(train_caret_v4$v2)
levels(valid_caret_v4$v37) = levels(train_caret_v4$v37)
levels(valid_caret_v4$v27) = levels(train_caret_v4$v27)
levels(valid_caret_v4$v21) = levels(train_caret_v4$v21)
levels(valid_caret_v4$v35) = levels(train_caret_v4$v35)
PREDICTION = predict(model_RF_TRUE, newdata=valid_caret_v4[!names(valid_caret_v4) %in% c("classLabel")])
confusionMatrix(PREDICTION,valid_caret_v4[,"classLabel"])
model_RF_TRUE = randomForest(x = train_caret_v4[,!names(train_caret_v4) %in% c("classLabel")], y=train_caret_v4$classLabel, mtry = c(2:6), ntree=188, importance=TRUE, metric="ROC", proximity=TRUE)
PREDICTION = predict(model_RF_TRUE, newdata=valid_caret_v4[!names(valid_caret_v4) %in% c("classLabel")])
confusionMatrix(PREDICTION,valid_caret_v4[,"classLabel"])
model_RF_TRUE = randomForest(x = train_caret_v4[,!names(train_caret_v4) %in% c("classLabel")], y=train_caret_v4$classLabel, mtry = c(2:6), ntree=500, importance=TRUE, metric="ROC", proximity=TRUE)
PREDICTION = predict(model_RF_TRUE, newdata=valid_caret_v4[!names(valid_caret_v4) %in% c("classLabel")])
confusionMatrix(PREDICTION,valid_caret_v4[,"classLabel"])
train_caret_v4 = train_caret_v3
valid_caret_v4 = valid_caret_v2
levels(valid_caret_v4$v9) = levels(train_caret_v4$v9)
levels(valid_caret_v4$v20) = levels(train_caret_v4$v20)
levels(valid_caret_v4$v41) = levels(train_caret_v4$v41)
levels(valid_caret_v4$v31) = levels(train_caret_v4$v31)
levels(valid_caret_v4$v36) = levels(train_caret_v4$v36)
levels(valid_caret_v4$v2) = levels(train_caret_v4$v2)
levels(valid_caret_v4$v37) = levels(train_caret_v4$v37)
levels(valid_caret_v4$v27) = levels(train_caret_v4$v27)
levels(valid_caret_v4$v21) = levels(train_caret_v4$v21)
levels(valid_caret_v4$v35) = levels(train_caret_v4$v35)
control <- trainControl(method="cv", number=10, repeats=5, classProbs = TRUE)
model_RF_TRUE = randomForest(x = train_caret_v4[,!names(train_caret_v4) %in% c("classLabel")], y=train_caret_v4$classLabel, mtry = c(2:6), ntree=500, importance=TRUE, metric="ROC", proximity=TRUE)
PREDICTION = predict(model_RF_TRUE, newdata=valid_caret_v4[!names(valid_caret_v4) %in% c("classLabel")])
confusionMatrix(PREDICTION,valid_caret_v4[,"classLabel"])
mtry <- tuneRF(train_caret_v4[!names(train_caret) %in% c("classLabel")],train_caret_v4$classLabel, ntreeTry=200,
stepFactor=1.5,improve=0.01, trace=TRUE, plot=TRUE)
best.m <- mtry[mtry[, 2] == min(mtry[, 2]), 1]
print(mtry)
print(best.m)
rf <-randomForest(classLabel~.,data=train_caret_v4, mtry=best.m, importance=TRUE,ntree=200)
print(rf)
importance(rf)
varImpPlot(rf)
par(mfrow = c(3, 5), mar = c(2, 2, 2, 2), pty = "s");
for (i in 1:(ncol(train_caret_v4) - 1))
{
partialPlot(rf, train_caret_v4, names(train_caret_v4)[i], xlab = names(train_caret_v4)[i],
main = NULL);
}
?partialPlot
impvar = varImp(rf)
impvar
impvar <- rownames(imp)[order(imp[, 1], decreasing=TRUE)]
imp = importance(rf)
impvar <- rownames(imp)[order(imp[, 1], decreasing=TRUE)]
impvar
par(mfrow = c(3, 5), mar = c(2, 2, 2, 2), pty = "s");
for (i in seq_along(impvar))
{
partialPlot(rf, train_caret_v4, names(train_caret_v4)[i], xlab = names(train_caret_v4)[i],
main = NULL);
}
model_RF = train(classLabel~., data=train_caret_v4, method="rf", preProcess="range", trControl=control, tuneGrid = expand.grid(.mtry = 4),  n.tree=188, maxit=2000, importance=TRUE, metric="ROC", proximity=TRUE)
PREDICTION = predict(model_RF, newdata=valid_caret_v4[!names(valid_caret_v4) %in% c("classLabel")])
confusionMatrix(PREDICTION,valid_caret_v4[,"classLabel"])
model_RF_TRUE = randomForest(x = train_caret_v4[,!names(train_caret_v4) %in% c("classLabel")], y=train_caret_v4$classLabel, mtry = 4, ntree=188, importance=TRUE, metric="ROC", proximity=TRUE)
PREDICTION = predict(model_RF_TRUE, newdata=valid_caret_v4[!names(valid_caret_v4) %in% c("classLabel")])
confusionMatrix(PREDICTION,valid_caret_v4[,"classLabel"])
control <- trainControl(method="cv", number=10, repeats=5, classProbs = TRUE)
gbmGrid <-  expand.grid(interaction.depth = c(1, 5, 9),
n.trees = (1:30)*50,
shrinkage = 0.1,
n.minobsinnode = 20)
model_GBM = train(classLabel~., data=train_caret_v4, method="gbm", trControl=control, tuneGrid=gbmGrid, metric="ROC")
PREDICTION = predict(model_GBM, newdata=valid_caret_v4[,!names(valid_caret_v4) %in% c("classLabel")])
confusionMatrix(PREDICTION,valid_caret_v4[,"classLabel"])
PREDICTION = predict(model_RF_TRUE, newdata=valid_caret_v4[!names(valid_caret_v4) %in% c("classLabel")])
confusionMatrix(PREDICTION,valid_caret_v4[,"classLabel"])
PREDICTION = predict(model_RF, newdata=valid_caret_v4[!names(valid_caret_v4) %in% c("classLabel")])
confusionMatrix(PREDICTION,valid_caret_v4[,"classLabel"])
library("ada")
install.packages("ada")
library("ada")
library(adabag)
BC.adaboost <- train(classLabel~., data=train_caret_v4, method="AdaBoost.M1", preProcess="range", trControl=control,  importance=TRUE, metric="ROC")
?ksvm
?train
lpSVM <- list(type = "Classification",
library = "kernlab",
loop = NULL)
prm <- data.frame(parameter = c("C", "sigma"),
class = rep("numeric", 2),
label = c("Cost", "Sigma"))
lpSVM$parameters <- prm
svmGrid <- function(x, y, len = NULL, search = "grid") {
library(kernlab)
## This produces low, middle and high values for sigma
## (i.e. a vector with 3 elements).
sigmas <- sigest(as.matrix(x), na.action = na.omit, scaled = TRUE)
## To use grid search:
if(search == "grid") {
out <- expand.grid(sigma = mean(as.vector(sigmas[-2])),
C = 2 ^((1:len) - 3))
} else {
## For random search, define ranges for the parameters then
## generate random values for them
rng <- extendrange(log(sigmas), f = .75)
out <- data.frame(sigma = exp(runif(len, min = rng[1], max = rng[2])),
C = 2^runif(len, min = -5, max = 8))
}
out
}
lpSVM$grid <- svmGrid
svmFit <- function(x, y, wts, param, lev, last, weights, classProbs, ...) {
ksvm(x = as.matrix(x), y = y,
kernel = rbfdot,
kpar = list(sigma = param$sigma),
C = param$C,
prob.model = classProbs,
...)
}
lpSVM$fit <- svmFit
svmPred <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata)
lpSVM$predict <- svmPred
svmProb <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
predict(modelFit, newdata, type="probabilities")
lpSVM$prob <- svmProb
svmSort <- function(x) x[order(x$C),]
lpSVM$sort <- svmSort
lpSVM$levels <- function(x) lev(x)
fitControl <- trainControl(method = "repeatedcv",
## 10-fold CV...
number = 10,
## repeated ten times
repeats = 10)
Laplacian <- train(classLabel ~ ., data = train_caret_v4,
method = lpSVM,
preProc = c("center", "scale"),
tuneLength = 8,
trControl = fitControl)
print(Laplacian, digits = 3)
PREDICTION = predict(Laplacian, newdata=valid_caret_v4[,!names(valid_caret_v4) %in% c("classLabel")])
confusionMatrix(PREDICTION,valid_caret_v4[,"classLabel"])
model_treebag <- train(classLabel ~ ., data = train_caret_v4,
method = "treebag",
nbagg = 50,
metric = "ROC",
trControl = control)
PREDICTION = predict(model_treebag, newdata=valid_caret_v4[,!names(valid_caret_v4) %in% c("classLabel")])
confusionMatrix(PREDICTION,valid_caret_v4[,"classLabel"])
