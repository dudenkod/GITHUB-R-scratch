---
title: "Classification Challenge by KrediTech"
author: "Dmytro Dudenko"
date: "30. April 2016"
output: html_document
---

Let's see and touch a bit the training data

```{r}
library(doMC)

train = read.csv(file="Training.csv", header = TRUE,  fill=TRUE, sep = ';')
valid = read.csv(file="Validation.csv", header = TRUE, fill = TRUE, sep = ';')
summary(train)
str(train)
```
We can see NA's, let's try to get them sorted.
Factors will just keep empty, numeric columns will try to replace with approximate values



```{r, echo=FALSE}

train_clean = train
valid_clean = valid

summary(train_clean)
str(train_clean)

train_clean$v17 = as.numeric(train_clean$v17)
train_clean$v19 = as.numeric(train_clean$v19)
train_clean$v29 = as.numeric(train_clean$v29)
train_clean$v17[is.na(train_clean$v17)] = mean(train_clean$v17,na.rm=T)
train_clean$v18[is.na(train_clean$v18)] = mean(train_clean$v18,na.rm=T)
train_clean$v39[is.na(train_clean$v39)] = mean(train_clean$v39,na.rm=T)


valid_clean$v17 = as.numeric(valid_clean$v17)
valid_clean$v19 = as.numeric(valid_clean$v19)
valid_clean$v29 = as.numeric(valid_clean$v29)
valid_clean$v17[is.na(valid_clean$v17)] = mean(valid_clean$v17,na.rm=T)
valid_clean$v18[is.na(valid_clean$v18)] = mean(valid_clean$v18,na.rm=T)
valid_clean$v39[is.na(valid_clean$v39)] = mean(valid_clean$v39,na.rm=T)

summary(valid_clean)
str(valid_clean)

```

Now we can start trying different models for supervised learning


```{r, echo=FALSE, message = F, error = F, warning = F}

train_clean_subset = subset(train_clean, select=c("v17","v29", "v19", "v12", "v39","v34"))
valid_clean_subset = subset(valid_clean, select=c("v17","v29", "v19", "v12", "v39","v34"))


train_clean_subset$binaryclass = ifelse(train_clean$classLabel == 'no.', 0,1)
valid_clean_subset$binaryclass = ifelse(valid_clean$classLabel == 'no.',0,1)
#train_clean_subset$binaryclass = train_clean$classLabel
#valid_clean_subset$binaryclass = valid_clean$classLabel

str(train_clean_subset)
#model_lm = step(lm(binaryclass ~ v17+v29+v19+v12+v39+v34, data = train_clean_subset), direction = "backward", trace=0)
model_lm = step(lm(binaryclass ~ v17+v29+v19+v12+v39+v34, data = train_clean_subset[1:500,]), direction = "backward", trace=0)

summary(model_lm)


fitted_lm = predict(model_lm,newdata=subset(valid_clean_subset,select=c(1,2,3,4,5,6)),type='response')

#fitted_lm <- ifelse(fitted_lm > 0.5,'yes.','no.')
fitted_lm <- ifelse(fitted_lm > 0.5,1,0)

misClasificError_lm <- mean(fitted_lm != valid_clean_subset$binaryclass)

print(paste('Accuracy',1-misClasificError_lm))

###End of LM

###GLM

library(mlbench)

correlationMatrix <- cor(train_clean_subset)
print(correlationMatrix)

train_clean_subset$binaryclass = as.factor(train_clean_subset$binaryclass)
control <- trainControl(method="repeatedcv", number=10, repeats=3)
model_glm <- train(binaryclass~., data=train_clean_subset[1:500,], method="glm", preProcess=c("center", "scale"), trControl=control)

importance <- varImp(model_glm, scale=FALSE)
# summarize importance
print(importance)
# plot importance
plot(importance)

fitted_glm = predict(model_glm,newdata=subset(valid_clean_subset,select=c(1,2,3,4,5,6)),type='raw')
fitted_glm = as.factor(fitted_glm)

misClasificError_glm <- mean(fitted_glm != valid_clean_subset$binaryclass)
print(paste('Accuracy',1-misClasificError_glm))

model_glm_final = train(binaryclass~v19+v12+v34 , data=train_clean_subset[1:500,], method="glm", preProcess=c("center", "scale"), trControl=control)
fitted_glm_final = predict(model_glm_final,newdata=subset(valid_clean_subset,select=c("v19","v12", "v34")),type='raw')

misClasificError_glm_final <- mean(fitted_glm_final != valid_clean_subset$binaryclass)
print(paste('Accuracy',1-misClasificError_glm_final))


library(caret)


control <- rfeControl(functions=rfFuncs, method="cv", number=10)
# run the RFE algorithm
results <- rfe(train_clean_subset[1:500,-7], train_clean_subset[1:500,7], sizes=c(1:6), rfeControl=control)
# summarize the results
print(results)
# list the chosen features
predictors(results)
# plot the results
plot(results, type=c("g", "o"))

control <- trainControl(method="repeatedcv", number=10, repeats=5)
model_rf <- train(binaryclass~ v12 + v34 + v19 + v29 + v39 + 1, data=train_clean_subset[1:500,], method="rf", preProcess=c("center", "scale"), trControl=control)
importance <- varImp(model_rf, scale=FALSE)
# summarize importance
print(importance)
# plot importance
plot(importance)

fitted_rf = predict(model_rf,newdata=valid_clean_subset,type='raw')


misClasificError_rf <- mean(fitted_rf != valid_clean_subset$binaryclass)

print(paste('Accuracy',1-misClasificError_rf))


#KNN
ctrl <- trainControl(method = "repeatedcv",
                     repeats = 5)


model_knn <- train(binaryclass ~ v12 + v34 + v19 + v29 +1, data = train_clean_subset[1:500,],
             method = "knn",
             trControl = ctrl)

importance <- varImp(model_rf, scale=FALSE)
# summarize importance
print(importance)
# plot importance
plot(importance)

fitted_knn = predict(model_knn,newdata=valid_clean_subset,type='raw')


misClasificError_knn <- mean(fitted_knn != valid_clean_subset$binaryclass)

print(paste('Accuracy',1-misClasificError_knn))


####all features analysis
train_clean_subset$v2 = train_clean$v2
train_clean_subset$v21 = train_clean$v21
train_clean_subset$v37 = train_clean$v37
train_clean_subset$v7 = train_clean$v7
train_clean_subset$v27 = train_clean$v27
valid_clean_subset$v2 = valid_clean$v2
valid_clean_subset$v21 = valid_clean$v21
valid_clean_subset$v37 = valid_clean$v37
valid_clean_subset$v7 = valid_clean$v7
valid_clean_subset$v27 = valid_clean$v27
train_clean_subset$binaryclass = train_clean$classLabel
valid_clean_subset$binaryclass = valid_clean$classLabel

control <- rfeControl(functions=rfFuncs, method="cv", number=10)
# run the RFE algorithm
results <- rfe(train_clean_subset[1:500,-12], train_clean_subset[1:500,12], sizes=c(1:11), rfeControl=control)
# summarize the results
print(results)
# list the chosen features
predictors(results)
# plot the results
plot(results, type=c("g", "o"))


###KNN with most factor features
#KNN
ctrl <- trainControl(method = "repeatedcv",
                     repeats = 5)


model_knn <- train(binaryclass ~ v7 + 1, data = train_clean_subset[1:500,],
             method = "knn",
             trControl = ctrl)

importance <- varImp(model_knn, scale=FALSE)
# summarize importance
print(importance)
# plot importance
plot(importance)

fitted_knn = predict(model_knn,newdata=valid_clean_subset,type='raw')


misClasificError_knn <- mean(fitted_knn != valid_clean_subset$binaryclass)

print(paste('Accuracy',1-misClasificError_knn))

##RF
control <- trainControl(method="repeatedcv", number=10, repeats=5)
#model_rf <- train(binaryclass~ v12 + v34 + v19 + v29 + v39 + v7, data=train_clean_subset[1:500,], method="rf",  trControl=control)
model_rf <- train(binaryclass~ v2 + v7, data=train_clean_subset[1:500,], method="rf",  trControl=control)
importance <- varImp(model_rf, scale=FALSE)
# summarize importance
print(importance)
# plot importance
plot(importance)

fitted_rf = predict(model_rf,newdata=valid_clean_subset[1:500,],type='raw')


misClasificError_rf <- mean(fitted_rf != valid_clean_subset$binaryclass)

print(paste('Accuracy',1-misClasificError_rf))

#GLM
control <- trainControl(method="repeatedcv", number=10, repeats=3)
model_glm_final = train(binaryclass~. , data=train_clean_subset[1:500,], method="glm", trControl=control)
#fitted_glm_final = predict(model_glm_final,newdata=subset(valid_clean_subset,select=c("v19","v12", "v34")),type='raw')
fitted_glm_final = predict(model_glm_final,newdata=valid_clean_subset[1:500,-12],type='raw')
misClasificError_glm_final <- mean(fitted_glm_final != valid_clean_subset$binaryclass)
print(paste('Accuracy',1-misClasificError_glm_final))


library("ggvis")
train_clean %>% ggvis(~v7, ~v21,  fill = ~classLabel) %>% layer_points()
valid_clean %>% ggvis(~v7, ~v21, fill = ~classLabel) %>% layer_points()

library(ROCR)
p <- predict(model_glm_final, newdata=valid_clean_subset[1:500,-12], type="raw")
pp = ifelse(p == 'yes.',1,0)
pr <- prediction(pp, valid_clean_subset$binaryclass)
prf <- performance(pr, measure = "tpr", x.measure = "fpr")
plot(prf)

auc <- performance(pr, measure = "auc")
auc <- auc@y.values[[1]]
auc

v21```

In fact, only three features are important
